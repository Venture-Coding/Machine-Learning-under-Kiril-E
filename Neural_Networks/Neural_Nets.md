  
    
  
Types of Gradient Descents :  
i)   Batch GD  
ii)  Stochastic GD  
iii) Mini Batch GD (Combo)  

  
  
Recommended Readings :  

1.  Yann LeCun - Efficient Backprop (1998).([Paper](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf))  
2.  Xavier Glorot - Deep Sparse Rectifier Neural Networks (2011).([Rectifiers](http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf))  
3.  [CrossValidated](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications) (2015) Stackexchange list of cost functions - appns.  
4.  Andrew Trask - A neural network in 13 lines of Python.([2015](https://iamtrask.github.io/2015/07/27/python-network-part2/))  
5.  Michael Nielson - NN & DL chap2.html (2015) (Intro)
6.  Jay Cuo - Understanding CNN with a Mathematical Model (2016) ([Understand ReLU](https://arxiv.org/pdf/1609.04112.pdf))    
7.  Jianxin Wu - Introduction to CNN (2017) [Intro Dive](https://cs.nju.edu.cn/wujx/paper/CNN.pdf)   
8.  Kaiming He - Delving Deep into Rectifiers - Surpassing Human Level in ImageNet (2015) [Leaky ReLU](https://openaccess.thecvf.com/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf).  
9.  Dominik Scherer - Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition (2010) [[Pooling](http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf)]  
10.  Visualize your CNN in this beautiful tool. [2D](https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html) and [3D](https://www.cs.ryerson.ca/~aharley/vis/conv/) visualization of Conv , Poolnig, Fully Connected Layers.

