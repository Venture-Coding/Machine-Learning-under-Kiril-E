  
    
  
Types of Gradient Descents :  
i)   Batch GD  
ii)  Stochastic GD  
iii) Mini Batch GD (Combo)  

  
  
Recommended Readings :  

1.  Yann LeCun - Efficient Backprop (1998).  
2.  Xavier Glorot - Deep Sparse Rectifier Neural Networks (2011).  
3.  CrossValidated (2015) Stackexchange list of cost functions - appns.  
4.  Andrew Trask - A neural network in 13 lines of Python.(2015)  
5.  Michael Nielson - NN & DL chap2.html (2015)
6.  Jay Cuo - Understanding CNN with a Mathematical Model (2016)  
7.  Jianxin WU - Introduction to CNN (2017)
