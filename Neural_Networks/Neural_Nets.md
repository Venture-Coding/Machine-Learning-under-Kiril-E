  
    
  
Types of Gradient Descents :  
i)   Batch GD  
ii)  Stochastic GD  
iii) Mini Batch GD (Combo)  

  
  
Recommended Readings :  

1.  Yann LeCun - Efficient Backprop (1998).  
2.  Xavier Glorot - Deep Sparse Rectifier Neural Networks (2011).  
3.  CrossValidated (2015) Stackexchange list of cost functions - appns.  
4.  Andrew Trask - A neural network in 13 lines of Python.(2015)  
5.  Michael Nielson - NN & DL chap2.html (2015) (Intro)
6.  Jay Cuo - Understanding CNN with a Mathematical Model (2016) (Understand ReLU)    
7.  Jianxin Wu - Introduction to CNN (2017)    
8.  Kaiming He - Delving Deep into Rectifiers - Surpassing Human Level in ImageNet (2015) (Leaky ReLU).  
9.  
